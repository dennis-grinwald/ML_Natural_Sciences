{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperspectral Remote Sensing Scenes Anlysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework you are asked to analyse the images collected from saltelites with hyperspectral cameras from a particular earth region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation (20P)\n",
    "\n",
    "* Download the _Indian Pines_ dataset from the \n",
    "__[Hyperspectral Data](http://www.ehu.eus/ccwintco/index.php/Hyperspectral_Remote_Sensing_Scenes)__  website in order to perform the classification. - DONE\n",
    "\n",
    "* Split data into __train__ and __test__ set in proportions 80% to 20% - DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import scipy.io\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import matplotlib.pyplot as plt\n",
    "import spectral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Indian Pines data\n",
    "This scene was gathered by AVIRIS sensor over the Indian Pines test site in North-western Indiana and consists of 145*145 pixels and 224 spectral reflectance bands in the wavelength range 0.4â€“2.5 10^(-6) meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "raw_data = scipy.io.loadmat('Indian_pines_corrected.mat')['indian_pines_corrected']\n",
    "raw_ground_truth = scipy.io.loadmat('Indian_pines_gt.mat')['indian_pines_gt']\n",
    "\n",
    "# shapes\n",
    "print(f\"Data shape: {raw_data.shape}\")\n",
    "print(f\"Labels shape: {raw_ground_truth.shape}\")\n",
    "print(f\"Max. pixel value: {raw_data.max(2).shape}\")\n",
    "\n",
    "# plot some sample bands\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4,figsize=(20,10))\n",
    "i = np.random.randint(raw_data.shape[2])\n",
    "ax1.imshow(raw_data[:,:,i])\n",
    "ax1.set_title(f\"Band: {i}\")\n",
    "\n",
    "i = np.random.randint(raw_data.shape[2])\n",
    "ax2.imshow(raw_data[:,:,i])\n",
    "ax2.set_title(f\"Band: {i}\")\n",
    "\n",
    "i = np.random.randint(raw_data.shape[2])\n",
    "ax3.imshow(raw_data[:,:,i])\n",
    "ax3.set_title(f\"Band: {i}\")\n",
    "\n",
    "i = np.random.randint(raw_data.shape[2])\n",
    "ax4.imshow(raw_data[:,:,i])\n",
    "ax4.set_title(f\"Band: {i}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(raw_ground_truth)\n",
    "plt.title(\"Ground Truth of pine data_set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for split\n",
    "data = raw_data.reshape(-1,200)\n",
    "ground_truth = raw_ground_truth.reshape(-1)\n",
    "\n",
    "# removing class 0 data and labels\n",
    "data_no_zero = data[np.argwhere(ground_truth!=0)].reshape(-1,200)\n",
    "ground_truth_no_zero = ground_truth[np.argwhere(ground_truth!=0)]\n",
    "\n",
    "training_data = data_no_zero[:int(.8*data_no_zero.shape[0])]\n",
    "training_labels = ground_truth_no_zero[:int(.8*ground_truth_no_zero.shape[0])]\n",
    "\n",
    "test_data = data_no_zero[int(.8*data_no_zero.shape[0]):]\n",
    "test_labels = ground_truth_no_zero[int(.8*ground_truth_no_zero.shape[0]):]\n",
    "\n",
    "print(f\"Length of training set: {training_data.shape[0]}\")\n",
    "print(f\"Length of test set: {test_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Classification\n",
    "In this section we'll apply different algorithms from the **_sklearn_** package in order to do find the best classification error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Semi-supervised classification (40 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Use whole data set ?\n",
    "\n",
    "* Draw 10% datapoints from each class to be used as semi-supervised labels and fix them. - DONE\n",
    "\n",
    "* Perform the _Mixture of Gaussians_ (sklearn.mixture.GaussianMixture) clustering with full covariance matrices on the input space with the true number of classes. - DONE\n",
    "\n",
    "* Perform the _Spectral Clustering_ (sklearn.cluster.SpectralClustering) on the feature space with the RBF kernel for building the affinity matrix with the true number of classes. - DONE\n",
    "\n",
    "* Assign labels for each data point within a class using semi-supervised labels i.e. as maximum occurence within the class and compute the accuracy (sklearn.metrics.accuracy_score).  - DONE\n",
    "\n",
    "* Use the accuracy metric in order to make a _scorer_ (sklearn.metrics.make_scorer) and perform cross-validation parameter tuning with the grid search engine (_GridSearchCV_ class) for both models. - DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample 10% of each label class and fix them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distinct labels\n",
    "distinct_labels = np.unique(ground_truth_no_zero)\n",
    "\n",
    "# creates dictionary with indices of labeled class samples(10% of total class samples) from each class\n",
    "# key: class label, value: list of indices of corresponding class samples(10%)\n",
    "labeled_data_dict = dict()\n",
    "\n",
    "# creates dictionary with indices of unlabeled class samples(90% of total class samples) from each class\n",
    "# key: class label, value: list of indices of corresponding class samples(90%)\n",
    "unlabeled_data_dict = dict()\n",
    "\n",
    "# Get 10% of each class. Efficient loop, since we only iterate over indices\n",
    "for label in distinct_labels:\n",
    "    shuffled_indices = np.random.permutation(np.where(ground_truth_no_zero==label)[0])\n",
    "    labeled_data_dict[label] = shuffled_indices[:int(.1*len(shuffled_indices))]\n",
    "    unlabeled_data_dict[label] = shuffled_indices[int(.1*len(shuffled_indices)):]\n",
    "\n",
    "# build inv labeled_data_indices dict\n",
    "# key: data-sample index, value: assigned label\n",
    "inv_labeled_data_dict = dict()\n",
    "for k,v in labeled_data_dict.items():\n",
    "    for v2 in v:\n",
    "        inv_labeled_data_dict[v2] = k\n",
    "\n",
    "# labeled training data indices\n",
    "labeled_data_indices = np.concatenate(list(labeled_data_dict.values()))\n",
    "# unlabeled training data indices\n",
    "unlabeled_data_indices = np.concatenate(list(unlabeled_data_dict.values()))\n",
    "        \n",
    "# fixed labeled dataset\n",
    "labeled_data = data_no_zero[labeled_data_indices]\n",
    "labeled_data_labels = ground_truth_no_zero[labeled_data_indices]\n",
    " \n",
    "# fixed unlabeled data\n",
    "unlabeled_data = data_no_zero[unlabeled_data_indices]\n",
    "unlabeled_data_labels = ground_truth_no_zero[unlabeled_data_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of training data: {training_data.shape[0]}\")\n",
    "print(f\"Length of labeled data set: {labeled_data.shape[0]}\")\n",
    "print(f\"Length of unlabeled data set: {unlabeled_data.shape[0]}\")\n",
    "print(f\"Fraction of training data: {round(labeled_data.shape[0]*100 / data_no_zero.shape[0])} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMMClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, cov_type='full', max_iter=100, n_init=1):\n",
    "        self.cov_type = cov_type\n",
    "        self.max_iter = max_iter\n",
    "        self.n_init = n_init\n",
    "\n",
    "        self.gmm = GaussianMixture(\n",
    "            n_components=len(distinct_labels),\n",
    "            covariance_type=self.cov_type,\n",
    "            max_iter=self.max_iter,\n",
    "            n_init=self.n_init\n",
    "        )\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.gmm.fit(X)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X=unlabeled_data, y=inv_labeled_data_dict):\n",
    "        \"\"\"Assign label to each cluster, according to max occ. of labeled points within those clusters\n",
    "        Parameters:\n",
    "            - data\n",
    "            - labeled data\n",
    "        Returns:\n",
    "            - (re-)labeled gauss cluster predictions of unlabeled samples\n",
    "        \"\"\"\n",
    "        clustered_data_labels = self.gmm.predict(X)\n",
    "\n",
    "        # assign labels to each cluster based on max occurence of label of\n",
    "        # labeled data samples within that cluster\n",
    "        for cluster_id in np.unique(clustered_data_labels):\n",
    "            cluster_indices = np.argwhere(clustered_data_labels == cluster_id)\n",
    "            tmp_labels = []\n",
    "\n",
    "            for index in cluster_indices:\n",
    "                # get real data label if exists - only take labels from semi supervised data\n",
    "                try:\n",
    "                    tmp_label = y[index[0]]\n",
    "                    tmp_labels.append(tmp_label)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            if tmp_labels != []:\n",
    "                # get most frequent label\n",
    "                tmp_counts = np.bincount(tmp_labels)\n",
    "                max_label = np.argmax(tmp_counts)\n",
    "\n",
    "                # assign all cluster points to the max label\n",
    "                clustered_data_labels[cluster_indices] = max_label\n",
    "        y = clustered_data_labels\n",
    "\n",
    "        return y\n",
    "\n",
    "    def score(self, X, y_true=unlabeled_data_labels):\n",
    "        # predictions for unlabeled data samples\n",
    "        predictions = self.predict()\n",
    "        \n",
    "        return accuracy_score(predictions, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_gmm = GMMClassifier()\n",
    "classifier_gmm = classifier_gmm.fit(data)\n",
    "gmm_cluster_predictions = classifier_gmm.predict(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy score\n",
    "gauss_acc = accuracy_score(gmm_cluster_predictions, unlabeled_data_labels)\n",
    "print(f\"Accuracy using Gaussian Mixture Clustering: {100*gauss_acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning Hyper Parameters with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'cov_type': ['full', 'tied', 'diag', 'spherical'],\n",
    "    'max_iter': [100,10,1],\n",
    "    'n_init': [100,10,1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "            estimator=GMMClassifier(),\n",
    "            param_grid=params,\n",
    "            cv=3\n",
    ")\n",
    "\n",
    "grid = grid.fit(labeled_data)\n",
    "\n",
    "# Print best results\n",
    "print(f\"Best achieved val accuracy: {grid.best_score_}\")\n",
    "print(f\"Best hyperparams: {grid.best_params_}\")\n",
    "\n",
    "gmm_cluster_predictions = grid.predict(X=unlabeled_data)\n",
    "print(f\"Accuracy on unlabeled data with best hyperparam. setup: {accuracy_score(gmm_cluster_predictions, unlabeled_data_labels)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral clustering Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, affinity='rbf', gamma=1.0, assign_labels=\"kmeans\", full_labels=ground_truth):    \n",
    "        self.full_labels=full_labels\n",
    "        self.affinity=affinity \n",
    "        self.gamma=gamma\n",
    "        self.assign_labels=assign_labels\n",
    "        self.spec_clusterer = SpectralClustering(\n",
    "            n_clusters=len(distinct_labels),\n",
    "            affinity=self.affinity,\n",
    "            gamma=self.gamma,\n",
    "            assign_labels=self.assign_labels\n",
    "        )\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.train_labels = y\n",
    "        self.spec_clustering=self.spec_clusterer.fit(X)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, y=inv_labeled_data_dict):\n",
    "        \n",
    "        \"\"\"Assign label to each cluster, according to max occ. of labeled points within those clusters\n",
    "        Parameters:\n",
    "            - data\n",
    "            - labeled data\n",
    "        Returns:\n",
    "            - (re-)labeled gauss cluster predictions of unlabeled samples\n",
    "        \"\"\"\n",
    "        \n",
    "        clustered_data_labels = self.spec_clustering.labels_\n",
    "        \n",
    "        # assign labels to each cluster based on max occurence of label of \n",
    "        # labeled data samples within that cluster\n",
    "        for cluster_id in np.unique(clustered_data_labels):\n",
    "            cluster_indices = np.argwhere(clustered_data_labels == cluster_id)\n",
    "            tmp_labels = []\n",
    "    \n",
    "            for index in cluster_indices:\n",
    "                # get real data label if exists - only take labels from semi supervised data\n",
    "                try:\n",
    "                    tmp_label = y[index[0]]\n",
    "                    tmp_labels.append(tmp_label)\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "            if tmp_labels != []:\n",
    "                # get most frequent label\n",
    "                tmp_counts = np.bincount(tmp_labels)\n",
    "                max_label = np.argmax(tmp_counts)\n",
    "    \n",
    "                # assign all cluster points to the max label\n",
    "                clustered_data_labels[cluster_indices] = max_label\n",
    "            \n",
    "        y = clustered_data_labels\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def score(self, X=None, y=None):\n",
    "        predictions = self.predict()\n",
    "        y_true=self.train_labels\n",
    "\n",
    "        return accuracy_score(predictions, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_spectral = SpectralClassifier()\n",
    "classifier_spectral = classifier_spectral.fit(data, ground_truth)\n",
    "spec_cluster_predictions = classifier_spectral.predict()\n",
    "\n",
    "# Compute accuracy score\n",
    "spec_acc = accuracy_score(spec_cluster_predictions[unlabeled_data_indices], ground_truth[unlabeled_data_indices])\n",
    "print(f\"Accuracy using Spectral Clustering Classification: {100*spec_acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning Hyper Parameters with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'gamma': [1000,100,10,1,0.1,0.01],\n",
    "    'assign_labels': ['kmeans', 'discretize']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "            estimator=SpectralClassifier(),\n",
    "            param_grid=params,\n",
    "            cv=3\n",
    ")\n",
    "\n",
    "grid = grid.fit(data, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best results\n",
    "print(f\"Best achieved val accuracy: {grid.best_score_*100}%\")\n",
    "print(f\"Best hyperparams: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_predictions = grid.predict(inv_labeled_data_dict)\n",
    "# Compute accuracy score\n",
    "spec_acc = accuracy_score(spec_predictions[unlabeled_data_indices], ground_truth[unlabeled_data_indices])\n",
    "print(f\"Accuracy using Spectral Clustering Classification: {100*spec_acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Supervised classification (20 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run multiclass Support Vector Machine classification in order to find labels for the unlabeled pixels. - DONE\n",
    "\n",
    "* Compute the overall pixels-wise error for the data _test_ set. - DONE\n",
    "\n",
    "* Use this metric in order to make a _scorer_ (_sklearn.metrics.make_scorer_) and perform cross-validation parameter tuning with the grid search engine (_GridSearchCV_ class). - DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "svm.fit(training_data, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_predictions = svm.predict(test_data)\n",
    "svm_test_acc = accuracy_score(test_set_predictions, test_labels)\n",
    "print(f\"SVM test classification accuracy: {round(svm_test_acc*100,6)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning Hyper Parameters with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper-params to optimize\n",
    "params = [\n",
    "    {'C': [10, 1, 0.1], 'kernel': ['linear']},\n",
    "    {'C': [10, 1, 0.1], 'kernel': ['rbf'], 'gamma': ['scale', 'auto', 10, 1, 0.1]},\n",
    "    {'C': [10, 1, 0.1], 'kernel': ['poly'], 'degree': [3, 2, 1]},\n",
    "    {'C': [10, 1, 0.1], 'kernel': ['sigmoid']},\n",
    "]\n",
    "\n",
    "# Define scorer\n",
    "def test_scorer(test_data, test_labels):\n",
    "    score = accuracy_score(test_data, test_labels)\n",
    "    return score\n",
    "    \n",
    "accuracy_scorer = make_scorer(test_scorer, greater_is_better=True)\n",
    "\n",
    "svm_grid = GridSearchCV(\n",
    "    estimator=SVC(), \n",
    "    param_grid=params, \n",
    "    scoring=accuracy_scorer\n",
    ")\n",
    "\n",
    "svm_grid = svm_grid.fit(training_data, training_labels)\n",
    "\n",
    "print(svm_grid.best_score_)\n",
    "print(svm_grid.best_params_)\n",
    "test_predictions_svm = svm_grid.predict(test_data)\n",
    "\n",
    "test_acc = accuracy_score(test_predictions, test_labels)\n",
    "print(f\"Final Test accuracy after Grid Search: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualization (20 P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visualize your classification results as the __covermap__ (_spectral.imshow_ ) using different colors for each class and compare it visually with the __normal__ image representation. - TBD\n",
    "\n",
    "* Does your __covermap__ respresent the analysed data properly or not ? Compute the overall pixels-wise classification error - TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmm data\n",
    "gmm_preds = gmm_cluster_predictions\n",
    "gmm_predicted_ground_truth = copy.deepcopy(ground_truth)\n",
    "gmm_predicted_ground_truth[unlabeled_data_indices] = gmm_preds\n",
    "gmm_predicted_ground_truth = gmm_predicted_ground_truth.reshape(raw_data.shape[0],raw_data.shape[1])\n",
    "\n",
    "# spectral clustering data\n",
    "spec_\n",
    "\n",
    "# svm data\n",
    "pred_train_set_svm = svm.predict(training_data)\n",
    "pred_test_set_svm = test_set_predictions_svm\n",
    "preds = np.expand_dims(np.append(pred_train_set_svm, pred_test_set_svm),1)\n",
    "pred_ground_truth_svm = copy.deepcopy(ground_truth)\n",
    "pred_ground_truth_svm[np.argwhere(ground_truth!=0)] = preds_svm\n",
    "pred_ground_truth_svm = pred_ground_truth_svm.reshape(raw_data.shape[0],raw_data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the predicted maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4,figsize=(15,10))\n",
    "\n",
    "ax1.imshow(raw_ground_truth)\n",
    "ax1.set_title(\"Ground Truth\")\n",
    "\n",
    "ax2.imshow(pred_ground_truth)\n",
    "ax2.set_title(\"SVM predicted Labels\")\n",
    "\n",
    "ax3.imshow(gmm_predicted_ground_truth)\n",
    "ax3.set_title(\"GMM predicted Labels\")\n",
    "\n",
    "ax4.imshow(gmm_predicted_ground_truth)\n",
    "ax4.set_title(\"Spectral Clustering predicted Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:\n",
    "As we can see, the SVM classifier has already learned to well-predict the labels of the corresponding pixels, with only mediocre mistakes in some classes(green)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optional Task (+50 P)\n",
    "\n",
    "* Define your own Deep Neural Network Architecture in order to defeat the best model you've already found from the previous tasks. - TBD\n",
    "\n",
    "* Show that your resuls are better or similar to the results from the previous models empirically as well as visually. - TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial: Use Conv. Neural Network(pretrained)\n",
    "### max. SVM acc. to beat ~ 61.51%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "class NNClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp_size):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(200, 50)\n",
    "        self.fc2 = nn.Linear(50, 16)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        output = F.relu(self.fc1(x))\n",
    "        output = self.fc2(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset into torch-compatible objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_training_data = CustomDataset(\n",
    "    training_data[:int(training_data.shape[0]*0.8),:].astype(float), \n",
    "    training_labels[:int(training_data.shape[0]*0.8)]\n",
    ")\n",
    "\n",
    "torch_val_data = CustomDataset(\n",
    "    training_data[int(training_data.shape[0]*0.8):,:].astype(float), \n",
    "    training_labels[int(training_data.shape[0]*0.8):]\n",
    ")\n",
    "\n",
    "torch_test_data = CustomDataset(\n",
    "    test_data.astype(float), \n",
    "    test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(parameters):\n",
    "    # define torch data loaders\n",
    "    batch_size = parameters[0]\n",
    "    learning_rate = parameters[1]\n",
    "    weigh_decay = parameters[2]\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torch_training_data, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        torch_val_data, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Define Model\n",
    "    inp_size = batch_size * 200\n",
    "    epochs = 20\n",
    "    best_model = None\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    model = NNClassifier(inp_size)\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.SGD(\n",
    "        params=model.parameters(),\n",
    "        lr=0.001,\n",
    "        weight_decay=0.01\n",
    "    )\n",
    "\n",
    "    lambda1 = lambda epoch: 0.995 ** epoch\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "\n",
    "    # define loss\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for e, epoch in enumerate(range(epochs)):\n",
    "    \n",
    "        #scheduler.step()\n",
    "    \n",
    "        # evaluation loop\n",
    "        with torch.no_grad():\n",
    "            total = 0.0\n",
    "            correct_predicted = 0.0\n",
    "        \n",
    "            for i, (data, labels) in enumerate(val_loader):\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "                out = model(data)\n",
    "                predictions = out.max(1)[1]\n",
    "            \n",
    "                correct_predicted += (predictions == labels.squeeze()).sum()\n",
    "                total += labels.shape[0]\n",
    "        \n",
    "            val_acc = (correct_predicted.item() / total)\n",
    "            print(f\"EPOCH: {e}, validation accuracy: {val_acc*100}%\")\n",
    "        \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "        \n",
    "        # training loop\n",
    "        total_loss = 0.0\n",
    "        for i, (data, labels) in enumerate(train_loader):\n",
    "        \n",
    "            model.train()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "        \n",
    "            try:\n",
    "                loss = criterion(out, labels.squeeze())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            except:\n",
    "                continue\n",
    "        print(f\"EPOCH: {e}, total loss: {total_loss} \")\n",
    "    \n",
    "    return best_model, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rates = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
    "#batch_sizes = [100, 50, 25, 12, 6, 3]\n",
    "#weight_decays = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
    "\n",
    "learning_rates = [0.01]\n",
    "batch_sizes = [12]\n",
    "weight_decays = [0.005]\n",
    "\n",
    "param_list = list(itertools.product(*[batch_sizes, learning_rates, weight_decays]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "final_acc = 0.0\n",
    "final_model = None\n",
    "final_params = None\n",
    "\n",
    "for params in param_list:\n",
    "    \n",
    "    tmp_best_model, tmp_best_val_acc = train(params)\n",
    "    \n",
    "    if tmp_best_val_acc > final_acc:\n",
    "        print(f\"FOUND NEW TOP ACC:\")\n",
    "        print(f\"Validation Accuracy: {tmp_best_val_acc*100}%\")\n",
    "        final_acc = tmp_best_val_acc\n",
    "        final_model = copy.deepcopy(tmp_best_model)\n",
    "        final_params = params\n",
    "        \n",
    "        #data = scipy.io.loadmat('Indian_pines_corrected.mat')['indian_pines_corrected']\n",
    "        #out = tmp_best_model(torch.Tensor(data.reshape(-1, 200).astype(float))).max(1)[1]\n",
    "        #plt.imshow(out.reshape(145,145))\n",
    "        #plt.title(\"Predicted Image of Pine Data set\")\n",
    "        #plt.show()\n",
    "        #time.sleep(10)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        torch_test_data, \n",
    "        batch_size=10,\n",
    "        shuffle=True\n",
    ")        \n",
    "# Evaluate final Test accuracy\n",
    "pred_labels_nn = []\n",
    "with torch.no_grad():\n",
    "    total = 0.0\n",
    "    correct_predicted = 0.0\n",
    "        \n",
    "    for i, (data, labels) in enumerate(test_loader):\n",
    "        \n",
    "        out = final_model(data)\n",
    "        predictions = out.max(1)[1]\n",
    "        pred_labels_nn.append(predictions.detach().numpy())\n",
    "        \n",
    "        correct_predicted += (predictions == labels.squeeze()).sum()\n",
    "        total += len(labels)\n",
    "        \n",
    "    test_acc = (correct_predicted.item() / total)\n",
    "    print(f\"Final test accuracy: {test_acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_train_preds = \n",
    "nn_test_preds = np.concatenate(pred_labels_nn).shape\n",
    "nn_pic = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_set_svm = svm.predict(training_data)\n",
    "pred_test_set_svm = test_set_predictions_svm\n",
    "preds = np.expand_dims(np.append(pred_train_set_svm, pred_test_set_svm),1)\n",
    "pred_ground_truth_svm = copy.deepcopy(ground_truth)\n",
    "pred_ground_truth_svm[np.argwhere(ground_truth!=0)] = preds_svm\n",
    "pred_ground_truth_svm = pred_ground_truth_svm.reshape(raw_data.shape[0],raw_data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_nn[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
